{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f672a7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513a0ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/me744_project/.venv/lib/python3.12/site-packages/glob2/fnmatch.py:141: SyntaxWarning: invalid escape sequence '\\Z'\n",
      "  return '(?ms)' + res + '\\Z'\n",
      "/home/john/me744_project/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'validation' to '/home/john/fiftyone/coco-2017/validation' if necessary\n",
      "Downloading annotations to '/home/john/fiftyone/coco-2017/tmp-download/annotations_trainval2017.zip'\n",
      " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|    1.9Gb/1.9Gb [5.0s elapsed, 0s remaining, 638.1Mb/s]      \n",
      "Extracting annotations to '/home/john/fiftyone/coco-2017/raw/instances_val2017.json'\n",
      "Downloading 100 images\n",
      " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [1.3s elapsed, 0s remaining, 91.7 images/s]         \n",
      "Writing annotations for 100 downloaded samples to '/home/john/fiftyone/coco-2017/validation/labels.json'\n",
      "Dataset info written to '/home/john/fiftyone/coco-2017/info.json'\n",
      "You are running the oldest supported major version of MongoDB. Please refer to https://deprecation.voxel51.com for deprecation notices. You can suppress this exception by setting your `database_validation` config parameter to `False`. See https://docs.voxel51.com/user_guide/config.html#configuring-a-mongodb-connection for more information\n",
      "Loading 'coco-2017' split 'validation'\n",
      " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [159.5ms elapsed, 0s remaining, 633.7 samples/s] \n",
      "Dataset 'coco-2017-validation-100' created\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?notebook=True&subscription=5470942a-8ff8-466b-b21f-68316c572bee\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f6d83d17200>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome to\n",
      "\n",
      "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—\n",
      "â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â•šâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•\n",
      "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—     â–ˆâ–ˆâ•‘    â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—\n",
      "â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•     â–ˆâ–ˆâ•‘     â•šâ–ˆâ–ˆâ•”â•  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•\n",
      "â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘        â–ˆâ–ˆâ•‘      â–ˆâ–ˆâ•‘   â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—\n",
      "â•šâ•â•     â•šâ•â•â•šâ•â•        â•šâ•â•      â•šâ•â•    â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•â•â•â•šâ•â•â•â•â•â•â• v1.10.0\n",
      "\n",
      "If you're finding FiftyOne helpful, here's how you can get involved:\n",
      "\n",
      "|\n",
      "|  â­â­â­ Give the project a star on GitHub â­â­â­\n",
      "|  https://github.com/voxel51/fiftyone\n",
      "|\n",
      "|  ğŸš€ğŸš€ğŸš€ Join the FiftyOne Discord community ğŸš€ğŸš€ğŸš€\n",
      "|  https://community.voxel51.com/\n",
      "|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "# Load COCO dataset\n",
    "dataset = fo.zoo.load_zoo_dataset(\"coco-2017\", split=\"validation\", max_samples=100)\n",
    "\n",
    "# Launch the app for interactive visualization\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addb0952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "from utils import CocoSegmentationDataset, build_model, detection_collate\n",
    "from pathlib import Path\n",
    "\n",
    "# ROOT = Path(__file__).resolve().parent\n",
    "# DEF = {\n",
    "#     \"train_images\": ROOT / \"Car-Parts-Segmentation/trainingset/JPEGImages\",\n",
    "#     \"train_anno\": ROOT / \"Car-Parts-Segmentation/trainingset/annotations.json\",\n",
    "#     \"val_images\": ROOT / \"Car-Parts-Segmentation/testset/JPEGImages\",\n",
    "#     \"val_anno\": ROOT / \"Car-Parts-Segmentation/testset/annotations.json\",\n",
    "#     \"checkpoint\": ROOT / \"checkpoints/epoch_010.pth\",\n",
    "#     \"output_dir\": ROOT / \"visualizations\",\n",
    "# }\n",
    "\n",
    "\n",
    "# Load COCO dataset\n",
    "dataset = CocoSegmentationDataset(\n",
    "    \"Car-Parts-Segmentation/trainingset/JPEGImages\",\n",
    "    \"Car-Parts-Segmentation/trainingset/annotations.json\",\n",
    "    is_train=True,\n",
    ")\n",
    "# Launch the app for interactive visualization\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58ac4f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 231/231 [3.3s elapsed, 0s remaining, 69.4 samples/s]      \n",
      "[{'id': 1, 'name': 'apple', 'supercategory': 'fruit'}]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?notebook=True&subscription=99245594-0027-4528-a537-3cd5c25c6d26\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x71cc9a704e30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "# data_path=\"Car-Parts-Segmentation/trainingset/JPEGImages\"\n",
    "# labels_path=\"Car-Parts-Segmentation/trainingset/annotations.json\"\n",
    "data_path = \"Fuji-Apple-Segmentation/trainingset/JPEGImages\"\n",
    "labels_path = \"Fuji-Apple-Segmentation/trainingset/annotations.json\"\n",
    "coco_dataset = fo.Dataset.from_dir(\n",
    "    dataset_type=fo.types.COCODetectionDataset,\n",
    "    data_path=data_path,\n",
    "    labels_path=labels_path,\n",
    "    include_id=True,\n",
    ")\n",
    "\n",
    "# COCO categories are also imported\n",
    "print(coco_dataset.info[\"categories\"])\n",
    "# [{'id': 1, 'name': 'airplane', 'supercategory': None}, ...]\n",
    "\n",
    "# print(coco_dataset)\n",
    "session = fo.launch_app(coco_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb28b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4792eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Sample: {\n",
      "    'id': '690cd5e77ef2fa737739d5ff',\n",
      "    'media_type': 'image',\n",
      "    'filepath': '/home/john/me744_project/maskrcnn_coco/Car-Parts-Segmentation/trainingset/JPEGImages/train1.jpg',\n",
      "    'tags': [],\n",
      "    'metadata': <ImageMetadata: {\n",
      "        'size_bytes': None,\n",
      "        'mime_type': None,\n",
      "        'width': 512,\n",
      "        'height': 512,\n",
      "        'num_channels': None,\n",
      "    }>,\n",
      "    'created_at': datetime.datetime(2025, 11, 6, 17, 7, 51, 646000),\n",
      "    'last_modified_at': datetime.datetime(2025, 11, 6, 17, 7, 51, 646000),\n",
      "    'detections': <Detections: {\n",
      "        'detections': [\n",
      "            <Detection: {\n",
      "                'id': '690cd5e77ef2fa737739d5f9',\n",
      "                'attributes': {},\n",
      "                'tags': [],\n",
      "                'label': 'wheel',\n",
      "                'bounding_box': [0.193359375, 0.671875, 0.607421875, 0.15625],\n",
      "                'mask': None,\n",
      "                'mask_path': None,\n",
      "                'confidence': None,\n",
      "                'index': None,\n",
      "                'supercategory': '',\n",
      "                'iscrowd': False,\n",
      "                'isbbox': False,\n",
      "                'color': '#e45779',\n",
      "                'metadata': {},\n",
      "            }>,\n",
      "            <Detection: {\n",
      "                'id': '690cd5e77ef2fa737739d5fa',\n",
      "                'attributes': {},\n",
      "                'tags': [],\n",
      "                'label': 'front_left_door',\n",
      "                'bounding_box': [0.32421875, 0.4765625, 0.28125, 0.291015625],\n",
      "                'mask': None,\n",
      "                'mask_path': None,\n",
      "                'confidence': None,\n",
      "                'index': None,\n",
      "                'supercategory': '',\n",
      "                'iscrowd': False,\n",
      "                'isbbox': False,\n",
      "                'color': '#c2dd62',\n",
      "                'metadata': {},\n",
      "            }>,\n",
      "            <Detection: {\n",
      "                'id': '690cd5e77ef2fa737739d5fb',\n",
      "                'attributes': {},\n",
      "                'tags': [],\n",
      "                'label': 'front_left_light',\n",
      "                'bounding_box': [0.099609375, 0.62109375, 0.0859375, 0.064453125],\n",
      "                'mask': None,\n",
      "                'mask_path': None,\n",
      "                'confidence': None,\n",
      "                'index': None,\n",
      "                'supercategory': '',\n",
      "                'iscrowd': False,\n",
      "                'isbbox': False,\n",
      "                'color': '#c6361d',\n",
      "                'metadata': {},\n",
      "            }>,\n",
      "        ],\n",
      "    }>,\n",
      "    'segmentations': <Detections: {\n",
      "        'detections': [\n",
      "            <Detection: {\n",
      "                'id': '690cd5e77ef2fa737739d5fc',\n",
      "                'attributes': {},\n",
      "                'tags': [],\n",
      "                'label': 'wheel',\n",
      "                'bounding_box': [0.193359375, 0.671875, 0.607421875, 0.15625],\n",
      "                'mask': array([[False, False, False, ..., False, False, False],\n",
      "                       [False, False, False, ..., False, False, False],\n",
      "                       [False, False, False, ..., False, False, False],\n",
      "                       ...,\n",
      "                       [False, False, False, ..., False, False, False],\n",
      "                       [False, False, False, ..., False, False, False],\n",
      "                       [False, False, False, ..., False, False, False]], shape=(80, 311)),\n",
      "                'mask_path': None,\n",
      "                'confidence': None,\n",
      "                'index': None,\n",
      "                'supercategory': '',\n",
      "                'iscrowd': False,\n",
      "                'isbbox': False,\n",
      "                'color': '#e45779',\n",
      "                'metadata': {},\n",
      "            }>,\n",
      "            <Detection: {\n",
      "                'id': '690cd5e77ef2fa737739d5fd',\n",
      "                'attributes': {},\n",
      "                'tags': [],\n",
      "                'label': 'front_left_door',\n",
      "                'bounding_box': [0.32421875, 0.4765625, 0.28125, 0.291015625],\n",
      "                'mask': array([[False, False, False, ..., False, False, False],\n",
      "                       [False, False, False, ..., False, False, False],\n",
      "                       [False, False, False, ..., False, False, False],\n",
      "                       ...,\n",
      "                       [False, False, False, ..., False, False, False],\n",
      "                       [False, False, False, ..., False, False, False],\n",
      "                       [False, False, False, ..., False, False, False]], shape=(149, 144)),\n",
      "                'mask_path': None,\n",
      "                'confidence': None,\n",
      "                'index': None,\n",
      "                'supercategory': '',\n",
      "                'iscrowd': False,\n",
      "                'isbbox': False,\n",
      "                'color': '#c2dd62',\n",
      "                'metadata': {},\n",
      "            }>,\n",
      "            <Detection: {\n",
      "                'id': '690cd5e77ef2fa737739d5fe',\n",
      "                'attributes': {},\n",
      "                'tags': [],\n",
      "                'label': 'front_left_light',\n",
      "                'bounding_box': [0.099609375, 0.62109375, 0.0859375, 0.064453125],\n",
      "                'mask': array([[False, False, False, ..., False, False,  True],\n",
      "                       [False, False, False, ...,  True,  True, False],\n",
      "                       [False, False, False, ...,  True, False, False],\n",
      "                       ...,\n",
      "                       [ True,  True,  True, ..., False, False, False],\n",
      "                       [ True,  True,  True, ..., False, False, False],\n",
      "                       [ True, False, False, ..., False, False, False]], shape=(33, 44)),\n",
      "                'mask_path': None,\n",
      "                'confidence': None,\n",
      "                'index': None,\n",
      "                'supercategory': '',\n",
      "                'iscrowd': False,\n",
      "                'isbbox': False,\n",
      "                'color': '#c6361d',\n",
      "                'metadata': {},\n",
      "            }>,\n",
      "        ],\n",
      "    }>,\n",
      "    'coco_id': 1,\n",
      "}>\n",
      "{\n",
      "  \"filepath\": \"/home/john/me744_project/maskrcnn_coco/Car-Parts-Segmentation/trainingset/JPEGImages/train1.jpg\",\n",
      "  \"tags\": [],\n",
      "  \"metadata\": {\n",
      "    \"_cls\": \"ImageMetadata\",\n",
      "    \"width\": 512,\n",
      "    \"height\": 512\n",
      "  },\n",
      "  \"created_at\": {\n",
      "    \"$date\": \"2025-11-06T17:07:51.646Z\"\n",
      "  },\n",
      "  \"last_modified_at\": {\n",
      "    \"$date\": \"2025-11-06T17:07:51.646Z\"\n",
      "  },\n",
      "  \"detections\": {\n",
      "    \"_cls\": \"Detections\",\n",
      "    \"detections\": [\n",
      "      {\n",
      "        \"_id\": {\n",
      "          \"$oid\": \"690cd5e77ef2fa737739d5f9\"\n",
      "        },\n",
      "        \"_cls\": \"Detection\",\n",
      "        \"attributes\": {},\n",
      "        \"tags\": [],\n",
      "        \"label\": \"wheel\",\n",
      "        \"bounding_box\": [\n",
      "          0.193359375,\n",
      "          0.671875,\n",
      "          0.607421875,\n",
      "          0.15625\n",
      "        ],\n",
      "        \"supercategory\": \"\",\n",
      "        \"iscrowd\": false,\n",
      "        \"isbbox\": false,\n",
      "        \"color\": \"#e45779\",\n",
      "        \"metadata\": {}\n",
      "      },\n",
      "      {\n",
      "        \"_id\": {\n",
      "          \"$oid\": \"690cd5e77ef2fa737739d5fa\"\n",
      "        },\n",
      "        \"_cls\": \"Detection\",\n",
      "        \"attributes\": {},\n",
      "        \"tags\": [],\n",
      "        \"label\": \"front_left_door\",\n",
      "        \"bounding_box\": [\n",
      "          0.32421875,\n",
      "          0.4765625,\n",
      "          0.28125,\n",
      "          0.291015625\n",
      "        ],\n",
      "        \"supercategory\": \"\",\n",
      "        \"iscrowd\": false,\n",
      "        \"isbbox\": false,\n",
      "        \"color\": \"#c2dd62\",\n",
      "        \"metadata\": {}\n",
      "      },\n",
      "      {\n",
      "        \"_id\": {\n",
      "          \"$oid\": \"690cd5e77ef2fa737739d5fb\"\n",
      "        },\n",
      "        \"_cls\": \"Detection\",\n",
      "        \"attributes\": {},\n",
      "        \"tags\": [],\n",
      "        \"label\": \"front_left_light\",\n",
      "        \"bounding_box\": [\n",
      "          0.099609375,\n",
      "          0.62109375,\n",
      "          0.0859375,\n",
      "          0.064453125\n",
      "        ],\n",
      "        \"supercategory\": \"\",\n",
      "        \"iscrowd\": false,\n",
      "        \"isbbox\": false,\n",
      "        \"color\": \"#c6361d\",\n",
      "        \"metadata\": {}\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"segmentations\": {\n",
      "    \"_cls\": \"Detections\",\n",
      "    \"detections\": [\n",
      "      {\n",
      "        \"_id\": {\n",
      "          \"$oid\": \"690cd5e77ef2fa737739d5fc\"\n",
      "        },\n",
      "        \"_cls\": \"Detection\",\n",
      "        \"attributes\": {},\n",
      "        \"tags\": [],\n",
      "        \"label\": \"wheel\",\n",
      "        \"bounding_box\": [\n",
      "          0.193359375,\n",
      "          0.671875,\n",
      "          0.607421875,\n",
      "          0.15625\n",
      "        ],\n",
      "        \"mask\": {\n",
      "          \"$binary\": {\n",
      "            \"base64\": \"eJzt3LFKw1AUh/Hc1afIFoUOFhfxAdwUFwcnqTbiIFZScVGfwhe2Ig61aZr7pTcJ5/y/rS0Hcn4kQ0uar8vri6ubkL1l78W8XN5XxVlefNxNi0lePCyq12r2fLuo5uXP++ezp2W5en/5OHspV68PT48n+cl0ejTJP3PWQVZT+K3uIy/FC4T1Uh3YmIvfP2yW9hBHFwCoQfPmBgTq1Ty5EYFtM37gEEADmw83BNA05MINATQP2Ydj+++cMs62e/9aADhmpRbr1wGwKTu1YtsQYFOGEhup3f7/BdiUocRGarv/ugCbMlRqNqNuYiNF7B/YlEk3saEYQNSUQTe2f9yUe7bQacpQvbCZc2P7x065ZwsdpgwlNpTYUD2xWXNDAPFDxtgYgNjERhIbCgAEOmUosaHERiL7BzhlKLGhEABr6FX3mdhQYkMxALGJjdQf29Cb7jWxoRib+6/yTM09m344YkEAsYkNJDaU2FB0f99qYoOJDQXZvN+EKjYUVKM3mJtJbCio5v5PV2JDQbWIwYEWS1xqtoHWSh1lazs4zFbpg2re/yxP2eiDMKwE1fQgEHje+FbDV5tvNf60It9qidh6XmKAmJqeFohPHN9qHU4c12pNbmCyjwMeS/xyc4yWbXGLnE16gCOt09Xmk+wvt9da95rEvgHDOTUs\",\n",
      "            \"subType\": \"00\"\n",
      "          }\n",
      "        },\n",
      "        \"supercategory\": \"\",\n",
      "        \"iscrowd\": false,\n",
      "        \"isbbox\": false,\n",
      "        \"color\": \"#e45779\",\n",
      "        \"metadata\": {}\n",
      "      },\n",
      "      {\n",
      "        \"_id\": {\n",
      "          \"$oid\": \"690cd5e77ef2fa737739d5fd\"\n",
      "        },\n",
      "        \"_cls\": \"Detection\",\n",
      "        \"attributes\": {},\n",
      "        \"tags\": [],\n",
      "        \"label\": \"front_left_door\",\n",
      "        \"bounding_box\": [\n",
      "          0.32421875,\n",
      "          0.4765625,\n",
      "          0.28125,\n",
      "          0.291015625\n",
      "        ],\n",
      "        \"mask\": {\n",
      "          \"$binary\": {\n",
      "            \"base64\": \"eJzt3D1Ow0AQhuF1yyncGSQ3kdLAAehANBRUKBAjCkSQjWiAU3BhEv4ESTz7OzMfyrydt9mnXK08+3Z6fnJ2Ubkn99zMu+G6b47q5uVq0rR1c7PoH/vZ/eWin3er9ePZ3dAt14fb2UO3/N6fTA/bejKdHrT1a53UnitfFRPD/skWXlUihUWVbylpKqcp4sHilNQU8JTl5HoKazI9xTV5HgZOhodDk+Hh4aR6mDRonDQPmybNw8hJ8HBqEjy8nFgPsybWg8Vh18R5BDgxHglOhEeEE+6R4QR7hDihnh3lBHrEOGEeOU6QR5AT4pHkBHhEOX7PTnO8HmGOzyPN8XjEOaRHXkN6NDiER4Uz7jEO5VHijHm0OCMeNc7/8OhxtnoUOdtAqpxNjy4H3qPMWfdocyowzl+QtmUVsEeb8hGuR1vyGaxHG/IVqkfb8R2oR5vxk3nozEMHxjGPJ/PQQXq0Eb8yD515yMA45vFkHjpIDw4I87RqnrHMQ2ceMtDLFvOMZB46MI9D9YCAzENnHjowjzMPmXnozEMH5nHAHgSQeejAPM485inFMQ+4x61nHmTPBsc8Hg/aX/xoQw5oIzJoE0Rw82caHkIDN/iKNuKO9pgF2qM1LJ4UBgMoj1EMVIqRCSrPSAJxMiJUAtu/AzPKYHg=\",\n",
      "            \"subType\": \"00\"\n",
      "          }\n",
      "        },\n",
      "        \"supercategory\": \"\",\n",
      "        \"iscrowd\": false,\n",
      "        \"isbbox\": false,\n",
      "        \"color\": \"#c2dd62\",\n",
      "        \"metadata\": {}\n",
      "      },\n",
      "      {\n",
      "        \"_id\": {\n",
      "          \"$oid\": \"690cd5e77ef2fa737739d5fe\"\n",
      "        },\n",
      "        \"_cls\": \"Detection\",\n",
      "        \"attributes\": {},\n",
      "        \"tags\": [],\n",
      "        \"label\": \"front_left_light\",\n",
      "        \"bounding_box\": [\n",
      "          0.099609375,\n",
      "          0.62109375,\n",
      "          0.0859375,\n",
      "          0.064453125\n",
      "        ],\n",
      "        \"mask\": {\n",
      "          \"$binary\": {\n",
      "            \"base64\": \"eJy11DEKwjAUxvFm9RTZopBF2skDuCkuDk4SbcRBrCTiop7CC5sKRWrea74q/reE3xBC8h7z5WyxEtklu6rS+q1TE6lum7HSUu0qd3bmuK5caev9qTl4G/b93pxsWA/zXMuiGGl5l182yPAE6kIwRKhoQl2Kinao42kMOUpJkpKQpIwkKCdjysrY/oV2yB9on7N22B4X28PGkrOUxB8WbRlJWFbi/+rTdsKWTcm3TUt8ADUUki8LSnyo1j0BrJcd+w==\",\n",
      "            \"subType\": \"00\"\n",
      "          }\n",
      "        },\n",
      "        \"supercategory\": \"\",\n",
      "        \"iscrowd\": false,\n",
      "        \"isbbox\": false,\n",
      "        \"color\": \"#c6361d\",\n",
      "        \"metadata\": {}\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"coco_id\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "sample = coco_dataset.first()\n",
    "print(sample)\n",
    "import json\n",
    "\n",
    "print(json.dumps(sample.to_dict(), indent=2))\n",
    "\n",
    "# Get the absolute path of the current file\n",
    "\n",
    "with open(\"filename\", \"w\") as f:\n",
    "    json.dump(sample.to_dict(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b7b30f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'instances_val2017.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Load COCO annotations into DataFrame\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minstances_val2017.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     12\u001b[39m     coco_data = json.load(f)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Extract annotations and convert to DataFrame\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/me744_project/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'instances_val2017.json'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.tv_tensors import BoundingBoxes\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "import torchvision.transforms.v2 as transforms\n",
    "from PIL import Image\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load COCO annotations into DataFrame\n",
    "with open(\"instances_val2017.json\", \"r\") as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "# Extract annotations and convert to DataFrame\n",
    "annotations_df = pd.DataFrame(coco_data[\"annotations\"])\n",
    "images_df = pd.DataFrame(coco_data[\"images\"])\n",
    "categories_df = pd.DataFrame(coco_data[\"categories\"])\n",
    "\n",
    "# Merge dataframes\n",
    "annotation_df = pd.merge(annotations_df, images_df, left_on=\"image_id\", right_on=\"id\")\n",
    "\n",
    "# Convert bbox format [x, y, w, h] -> [x, y, x, y]\n",
    "bboxes = torch.Tensor([ann[\"bbox\"] for ann in coco_data[\"annotations\"]])\n",
    "converted_boxes = torchvision.ops.box_convert(bboxes, \"xywh\", \"xyxy\")\n",
    "\n",
    "# Visualize single image with bounding boxes\n",
    "image = Image.open(\"image_path.jpg\").convert(\"RGB\")\n",
    "img_tensor = transforms.PILToTensor()(image)\n",
    "\n",
    "# Create BoundingBoxes object\n",
    "boxes = BoundingBoxes(converted_boxes, format=\"xyxy\", canvas_size=image.size[::-1])\n",
    "\n",
    "# Draw boxes\n",
    "annotated_img = draw_bounding_boxes(\n",
    "    (img_tensor).to(dtype=torch.uint8),\n",
    "    boxes=boxes,\n",
    "    labels=[\"person\", \"dog\", \"cat\"],  # class names\n",
    "    colors=[\"red\", \"blue\", \"green\"],\n",
    "    width=2,\n",
    "    font_size=25,\n",
    ")\n",
    "\n",
    "# Display\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "to_pil_image(annotated_img).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf76215",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
